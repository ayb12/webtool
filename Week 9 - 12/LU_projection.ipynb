{"cells":[{"cell_type":"code","metadata":{"tags":[],"cell_id":"00000-0acfae4f-0b59-4e5f-91ae-82e3692a78a5"},"source":"import collections\nimport numpy as np\nfrom scipy.spatial import distance\n\nfrom globalfn.alignments import all_alignments, aligned_with\nfrom globalfn.annotations import annotation, all_annotations\n\nimport flair\nfrom flair.data import Sentence","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 1: Assume that LU can be directly projected\n\nOutput: a dictionary of projected LUs and their respective embeddings","metadata":{"tags":[],"cell_id":"00002-378c85da-4556-4158-b47b-f5dff993a267"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00002-093e54a9-4331-40d7-9e04-b55715048e4f"},"source":"from flair.embeddings import TransformerWordEmbeddings\nmbert = TransformerWordEmbeddings('bert-base-multilingual-cased')","execution_count":null,"outputs":[{"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e756e94210e4695bc249e1ef07797a4"}},"metadata":{},"output_type":"display_data"},{"name":"stdout","text":"\n","output_type":"stream"},{"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6cd904451594943b25b38a82dc4b30e"}},"metadata":{},"output_type":"display_data"},{"name":"stdout","text":"\n","output_type":"stream"},{"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c924cc677034d618c288af2a2f9dc0f"}},"metadata":{},"output_type":"display_data"},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00001-2330c19e-a7ce-4764-9dd2-ea02d40cc1e5"},"source":"def generate_embeddings(lang):\n    \"\"\"\n    Outputs:\n    # ID_to_embeddings - {sentence ID: mBERT word embeddings}\n    # ID_to_LU_embeddings - {sentence ID: [(word_idx, LU, embedding, frame)]}\n    \"\"\"\n    ID_to_embeddings = {}\n    ID_to_LU_embeddings = collections.defaultdict(list)\n    for sent_ID, annos in all_annotations(lang).items():\n        tokenized_text = Sentence(annos[0].tokenized_text)\n        mbert.embed(tokenized_text)\n        embeddings = [token.embedding.cpu().numpy() for token in tokenized_text]\n        ID_to_embeddings[sent_ID] = embeddings\n        for anno in annos:\n            for i, lu in enumerate(anno.tokenized_lu_idx):\n                if lu is not \"-\":\n                    ID_to_LU_embeddings[sent_ID].append((i, lu, embeddings[i], anno.frameName))\n\n    return ID_to_embeddings, ID_to_LU_embeddings\n\nen_ID_to_embeddings, en_ID_to_LU_embeddings = generate_embeddings('en')\npt_ID_to_embeddings, pt_ID_to_LU_embeddings = generate_embeddings('pt')","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00002-9bb2e912-8acc-4b74-afae-9494514b9e6f"},"source":"def find_projected_embeddings(src_ID_to_LU_embeddings, tgt_ID_to_embeddings, tgt_lang):\n    \"\"\"\n    Outputs:\n    # ID_to_projected_LU_embeddings - {sentence ID: [(word_idx, projected word, embedding)]}\n    \"\"\"\n    ID_to_projected_LU_embeddings = collections.defaultdict(list)\n    for src_ID in src_ID_to_LU_embeddings.keys():\n        src_IDs, tgt_IDs = aligned_with(src_ID, tgt_lang)\n        for _, _, src_LU_embedding, _ in src_ID_to_LU_embeddings[src_ID]:\n            for tgt_ID in tgt_IDs:\n                if tgt_ID in tgt_ID_to_embeddings:\n                    # word embeddings for the word token in the sentence\n                    tgt_word_embeddings = tgt_ID_to_embeddings[tgt_ID]\n\n                    # find the closest LU with respect to cosine similarity\n                    distances = distance.cdist([src_LU_embedding], tgt_word_embeddings, \"cosine\")[0]\n                    min_index = np.argmin(distances)\n\n                    projected_word = annotation(tgt_ID)[0].tokenized_text.split(' ')[min_index]\n                    ID_to_projected_LU_embeddings[tgt_ID].append((min_index, projected_word, tgt_word_embeddings[min_index]))\n    return ID_to_projected_LU_embeddings\n\npt_ID_to_projected_LU_embeddings = find_projected_embeddings(en_ID_to_LU_embeddings, pt_ID_to_embeddings, 'pt')\nen_ID_to_projected_LU_embeddings = find_projected_embeddings(pt_ID_to_LU_embeddings, en_ID_to_embeddings, 'en')","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00005-af16cd44-8182-47a2-835b-eafba262010f"},"source":"print(pt_ID_to_projected_LU_embeddings.keys())\nprint(en_ID_to_projected_LU_embeddings.keys())","execution_count":null,"outputs":[{"name":"stdout","text":"dict_keys([739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 834, 835, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 862, 863, 864, 865, 866, 867, 868, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 883, 885, 886, 887, 888, 889, 890, 891, 892, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 961, 962, 963, 964, 965, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 749, 777, 778, 830, 836, 838, 861, 869, 882, 884, 893, 908, 909, 956, 966])\ndict_keys([1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1098, 1099, 1100, 1101, 1102, 1104, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1152, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Step 2: SDEC-AD Semantic Frame Induction","metadata":{"tags":[],"cell_id":"00006-d6a8b7af-8a5d-4710-89ee-860aaffbc2b7"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00007-dcedfb30-0605-4164-89fa-74448f0e69f7"},"source":"import pickle\nfrom SDEC.models.SDEC_AD import DeepEmbeddingClustering\nimport nltk\nnltk.download('stopwords')\nnltk.download('framenet_v17')\nfrom nltk.corpus import framenet as fn\nfrom nltk.corpus import stopwords\n\nfn_lu_embedding_filename = \"lus_fn1.7_definition_bert.p\"\nfn_L = pickle.load(open(fn_lu_embedding_filename, 'rb'))\nframes_to_int = {}\nint_to_frames = {}\nfor lu_id in fn_L.keys():\n    frame_name = fn.lu(lu_id).frame.name\n    if frame_name not in frames_to_int:\n        int_to_frames[len(frames_to_int)] = frame_name\n        frames_to_int[frame_name] = len(frames_to_int)","execution_count":null,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package framenet_v17 to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Unzipping corpora/framenet_v17.zip.\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00007-7cef5ea3-b16b-4769-8863-889539b3ce04"},"source":"def SDEC_frame_induction(ID_to_projected_LU_embeddings, ID_to_LU_embeddings, SDEC_trained_weights=None):\n    \"\"\"\n    Use SDEC to induce semantic frames from the embeddings of the projected lexical units.\n    Outputs:\n    # - sent_ID_SDEC_induced_frames: a dictionary of sentence IDs to the set of predicted semantic frames\n    # - sent_ID_annotated_frames: a dictionary of sentence IDs to the set of annotated semantic frames\n    \"\"\"\n    X = list()\n    ids = list()\n    for key in range(min(ID_to_projected_LU_embeddings.keys()), max(ID_to_projected_LU_embeddings.keys()) + 1):\n        for _, _, embedding in ID_to_projected_LU_embeddings[key]:\n            X.append(embedding)\n            ids.append(key)\n    \n    X = np.array(X)\n    c = DeepEmbeddingClustering(n_clusters=len(int_to_frames),\n                                input_dim=3072,\n                                encoders_dims=[7500, 1000])\n    pred_Y = c.predict(X, SDEC_trained_weights=SDEC_trained_weights)\n    sent_ID_SDEC_induced_frames = collections.defaultdict(set)\n    for i in range(len(ids)):\n        sent_ID_SDEC_induced_frames[ids[i]].add(int_to_frames[pred_Y[i]])\n\n    sent_ID_annotated_frames = collections.defaultdict(set)\n    for id in ID_to_LU_embeddings:\n        for _, _, _, frame in ID_to_LU_embeddings[id]:\n            if frame not in frames_to_int:\n                print(frame)\n            sent_ID_annotated_frames[id].add(frame)\n    return sent_ID_SDEC_induced_frames, sent_ID_annotated_frames","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00009-804da4c7-b2ad-4533-a41f-a0ab2e665bc4"},"source":"\"\"\"semantic frame induction for PT (whose LUs are projected from EN)\"\"\"\npt_pred, pt_true = SDEC_frame_induction(pt_ID_to_projected_LU_embeddings, pt_ID_to_LU_embeddings, \"/home/jovyan/work/SDEC-trained/SDEC_AD_bcubed_fscore_0.61633.h5\")","execution_count":null,"outputs":[{"name":"stdout","text":"Obligation_scenario\nPhysical_entity\nAsymmetric_reciprocality\nAsymmetric_reciprocality\nAsymmetric_reciprocality\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00010-13862988-e317-4980-bc34-67be5d5615e1"},"source":"\"\"\"semantic frame induction for EN (whose LUs are projected from PT)\"\"\"\nen_pred, en_true = SDEC_frame_induction(en_ID_to_projected_LU_embeddings, en_ID_to_LU_embeddings, \"/home/jovyan/work/SDEC-trained/SDEC_AD_bcubed_fscore_0.61633.h5\")","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 3: Evaluation of Semantic Frames Induction","metadata":{"tags":[],"cell_id":"00014-57826ce1-9b40-49ff-8d74-e742526426e9"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00015-ed3dc04f-84bf-4961-8f36-0b3e5f54bdab"},"source":"frames = set()\nfor frame in fn.frames():\n    frames.add(frame.name)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00015-9e803544-7275-4f8d-8781-24113867aef1"},"source":"def evaluate(pred, true, frames=frames, show_individual=False, print_result=True):\n    \"\"\"\n    Evaluate the precision, recall, and F1-scores of the predicted frames (`pred`) \n    and the actual frames (`true`).\n    \"\"\"\n    sum_prec = count_prec = 0\n    sum_recall = count_recall = 0\n    sum_f1 = count_f1 = 0\n\n    for ID in true.keys():\n        tp = fp = tn = fn = 0\n        for true_frame in true[ID]:\n            if true_frame in pred[ID]:\n                tp += 1\n            else:\n                fn += 1\n        \n        for pred_frame in pred[ID]:\n            if pred_frame not in true[ID]:\n                fp += 1\n        \n        tn = len(frames) - len(true[ID]) - fp\n        if tp + fp == 0:\n            prec = \"n/a\" # there were no positive cases in the input data\n        else:\n            prec = tp / (tp + fp)\n            sum_prec += prec\n            count_prec += 1\n\n        if tp + fn == 0:\n            recall = \"n/a\"\n        else:\n            recall = tp / (tp + fn)  # all instances were predicted as negative\n            sum_recall += recall\n            count_recall += 1\n\n        if prec == \"n/a\" or recall == \"n/a\":\n            f1 = \"n/a\"\n        elif prec == 0 and recall == 0:\n            f1 = 0\n        else:\n            f1 = 2*(prec*recall)/(prec + recall)\n            sum_f1 += f1\n            count_f1 += 1\n        \n        if show_individual:\n            print(f\"Precision:{prec}\\tRecall:{recall}\\tF1:{f1}\")\n    \n    if print_result:\n        print(\"-------------------\")\n        print(f\"Avg Precision: {sum_prec/count_prec:3f}\\nAvg Recall: {sum_recall/count_recall:3f}\\nF1: {sum_f1/count_f1:3f}\")\n        print(\"-------------------\")\n    return sum_f1/count_f1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00017-5d8ee757-062f-4f49-98e7-0a24218b9ac5"},"source":"evaluate(pt_pred, pt_true)","execution_count":null,"outputs":[{"name":"stdout","text":"-------------------\nAvg Precision: 0.323171\nAvg Recall: 0.218637\nF1: 0.387683\n-------------------\n","output_type":"stream"},{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"0.38768287999515677"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00018-6d3e8d5c-2d78-4dfb-9e47-19f416ada46a"},"source":"evaluate(en_pred, en_true)","execution_count":null,"outputs":[{"name":"stdout","text":"-------------------\nAvg Precision: 0.271881\nAvg Recall: 0.355575\nF1: 0.408168\n-------------------\n","output_type":"stream"},{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"0.4081684919460366"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00017-f2e19b9b-66d6-4e87-97e8-2011ed019259"},"source":"","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"a6cbcb1b-bd5b-4bd5-be8d-6c01a0e3e566","deepnote_execution_queue":[]}}