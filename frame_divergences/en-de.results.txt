===============================
====Annotation (`annoID` = 4257)====
text: So I have a big interest in education, and I think we all do.
frameName: Awareness
frameID: 14
luName: think.v
luID: 12780
lu_idx: [(45, 49, 1)]
fe_idx: [(43, 43, 'Cognizer', 57), (51, 59, 'Content', 58)]
tokenized_text: So I have a big interest in education , and I think we all do .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'think.v', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Awareness', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', '-', 'Content', 'Content', 'Content', '-']

====Annotation (`annoID` = 10790)====
text: Ich habe ein großes Interesse an Bildung, und ich denke, das haben wir alle.
frameName: Cogitation
frameID: 17
luName: denken.v
luID: 29776
lu_idx: [(50, 54, 1577)]
fe_idx: [(57, 74, 'Topic', 71), (46, 48, 'Cognizer', 70)]
tokenized_text: Ich habe ein großes Interesse an Bildung , und ich denke , das haben wir alle .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'denken.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Cogitation', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', '-', '-', 'Topic', 'Topic', 'Topic', 'Topic', '-']

===============================
====Annotation (`annoID` = 2553)====
text: My contention is that creativity now is as important in education as literacy, and we should treat it with the same status.
frameName: Statement
frameID: 37
luName: contention.n
luID: 13378
lu_idx: [(3, 12, 1)]
fe_idx: [(17, 121, 'Message', 154), (0, 1, 'Speaker', 152)]
tokenized_text: My contention is that creativity now is as important in education as literacy , and we should treat it with the same status .
tokenized_lu_idx: ['-', 'contention.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Speaker', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-']

====Annotation (`annoID` = 9316)====
text: Meine Überzeugung ist, dass Kreativität heute genauso wichtig für Bildung ist, wie Lesen und Schreiben, und wir sollten sie gleichwertig behandeln.
frameName: Opinion
frameID: 642
luName: überzeugung.n
luID: 29520
lu_idx: [(6, 16, 1577)]
fe_idx: [(0, 4, 'Cognizer', 5228), (23, 101, 'Opinion', 5229)]
tokenized_text: Meine Überzeugung ist , dass Kreativität heute genauso wichtig für Bildung ist , wie Lesen und Schreiben , und wir sollten sie gleichwertig behandeln .
tokenized_lu_idx: ['-', 'überzeugung.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', '-', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2439)====
text: Because it's one of those things that goes deep with people, am I right?
frameName: Causation
frameID: 1
luName: because.c
luID: 12518
lu_idx: [(0, 6, 1)]
fe_idx: [(8, 58, 'Cause', 3), (-1, -1, 'Effect', 5)]
tokenized_text: Because it 's one of those things that goes deep with people , am I right ?
tokenized_lu_idx: ['because.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9900)====
text: Denn es ist eines dieser Themen, die Leute tief berühren, wie Religion, Geld und andere Sachen.
frameName: Reason
frameID: 417
luName: denn.adv
luID: 29798
lu_idx: [(0, 3, 1577)]
fe_idx: [(5, 93, 'State_of_affairs', 3094)]
tokenized_text: Denn es ist eines dieser Themen , die Leute tief berühren , wie Religion , Geld und andere Sachen .
tokenized_lu_idx: ['denn.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Reason', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', '-']

===============================
====Annotation (`annoID` = 2546)====
text: But if you are, and you say to somebody, you know, they say, 'What do you do?'and you say you work in education, you can see the blood run from their face.
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(24, 26, 1)]
fe_idx: [(28, 38, 'Addressee', 153), (20, 22, 'Speaker', 152), (-1, -1, 'Message', 154)]
tokenized_text: But if you are , and you say to somebody , you know , they say , ' What do you do ?' and you say you work in education , you can see the blood run from their face .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Speaker', '-', 'Addressee', 'Addressee', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10377)====
text: Sind Sie aber eingeladen und reden mit jemandem, also wenn jemand fragt: 'Was machen Sie so?'und Sie: 'Ich arbeite im Bildungswesen', sieht man, wie den anderen das Blut aus dem Gesicht weicht.
frameName: Chatting
frameID: 477
luName: reden mit.v
luID: 29857
lu_idx: [(35, 37, 1577), (29, 33, 1577)]
fe_idx: [(5, 7, 'Interlocutor_1', 3863), (39, 46, 'Interlocutor_2', 3864)]
tokenized_text: Sind Sie aber eingeladen und reden mit jemandem , also wenn jemand fragt : ' Was machen Sie so ?' und Sie : ' Ich arbeite im Bildungswesen ' , sieht man , wie den anderen das Blut aus dem Gesicht weicht .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'reden mit.v', 'reden mit.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Chatting', 'Chatting', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Interlocutor_1', '-', '-', '-', '-', '-', 'Interlocutor_2', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2558)====
text: She went over to her, and she said, 'What are you drawing?'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(30, 33, 1)]
fe_idx: [(37, 56, 'Message', 154), (26, 28, 'Speaker', 152)]
tokenized_text: She went over to her , and she said , ' What are you drawing ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 9336)====
text: Die Lehrerin war fasziniert, ging zu ihr herüber und fragte: 'Was malst du denn da?'
frameName: Questioning
frameID: 34
luName: fragen.v
luID: 29491
lu_idx: [(53, 58, 1577)]
fe_idx: [(0, 11, 'Speaker', 136), (61, 83, 'Message', 138)]
tokenized_text: Die Lehrerin war fasziniert , ging zu ihr herüber und fragte : ' Was malst du denn da ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'fragen.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Questioning', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Speaker', 'Speaker', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message']

===============================
====Annotation (`annoID` = 4285)====
text: My contention is that creativity now is as important in education as literacy, and we should treat it with the same status.
frameName: Reading_perception
frameID: 254
luName: literacy.n
luID: 27221
lu_idx: [(69, 76, 1)]
fe_idx: [(-1, -1, 'Text', 1669), (-1, -1, 'Reader', 1668)]
tokenized_text: My contention is that creativity now is as important in education as literacy , and we should treat it with the same status .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'literacy.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Reading_perception', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10804)====
text: Meine Überzeugung ist, dass Kreativität heute genauso wichtig für Bildung ist, wie Lesen und Schreiben, und wir sollten sie gleichwertig behandeln.
frameName: Reading_activity
frameID: 1177
luName: lesen.n
luID: 30035
lu_idx: [(83, 87, 1577)]
fe_idx: []
tokenized_text: Meine Überzeugung ist , dass Kreativität heute genauso wichtig für Bildung ist , wie Lesen und Schreiben , und wir sollten sie gleichwertig behandeln .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'lesen.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Reading_activity', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2506)====
text: What you have there is a person of extraordinary dedication who found a talent.
frameName: Have_associated
frameID: 866
luName: have.v
luID: 24887
lu_idx: [(9, 12, 1)]
fe_idx: [(0, 3, 'Entity', 7984), (14, 18, 'Place', 7988), (5, 7, 'Topical_entity', 7993)]
tokenized_text: What you have there is a person of extraordinary dedication who found a talent .
tokenized_lu_idx: ['-', '-', 'have.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Have_associated', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Entity', 'Topical_entity', '-', 'Place', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9720)====
text: Sie ist eine Person mit außerordentlicher Hingabe, die ihr Talent gefunden hat.
frameName: Being_in_category
frameID: 813
luName: sein.v
luID: 29784
lu_idx: [(4, 6, 1577)]
fe_idx: [(0, 2, 'Item', 7395), (8, 48, 'Category', 7396)]
tokenized_text: Sie ist eine Person mit außerordentlicher Hingabe , die ihr Talent gefunden hat .
tokenized_lu_idx: ['-', 'sein.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Being_in_category', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Item', '-', 'Category', 'Category', 'Category', 'Category', 'Category', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2508)====
text: I have an interest in education.
frameName: Emotion_directed
frameID: 40
luName: interest.n
luID: 13643
lu_idx: [(10, 17, 1)]
fe_idx: [(0, 0, 'Experiencer', 163), (19, 30, 'Stimulus', 165)]
tokenized_text: I have an interest in education .
tokenized_lu_idx: ['-', '-', '-', 'interest.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Emotion_directed', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Stimulus', 'Stimulus', '-']

====Annotation (`annoID` = 10373)====
text: Ich interessiere mich für Bildung.
frameName: Experiencer_focus
frameID: 42
luName: interessiere mich.v
luID: 29853
lu_idx: [(17, 20, 1577), (4, 15, 1577)]
fe_idx: [(22, 32, 'Content', 169), (0, 2, 'Experiencer', 168)]
tokenized_text: Ich interessiere mich für Bildung .
tokenized_lu_idx: ['-', 'interessiere mich.v', 'interessiere mich.v', '-', '-', '-']
tokenized_frame_idx: ['-', 'Experiencer_focus', 'Experiencer_focus', '-', '-', '-']
tokenized_fe_idx: ['Experiencer', '-', '-', 'Content', 'Content', '-']

===============================
====Annotation (`annoID` = 4519)====
text: We were sitting there and I think they just went out of sequence, because we talked to the little boy afterward and we said, 'You OK with that?'
frameName: Opinion
frameID: 642
luName: think.v
luID: 23709
lu_idx: [(28, 32, 1)]
fe_idx: [(26, 26, 'Cognizer', 5228), (34, 63, 'Opinion', 5229)]
tokenized_text: We were sitting there and I think they just went out of sequence , because we talked to the little boy afterward and we said , ' You OK with that ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Cognizer', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10780)====
text: Wir saßen da und ich glaube, sie vertauschten die Reihenfolge, weil wir hinterher fragten: 'War das okay für dich?'und er: 'Ja.
frameName: Certainty
frameID: 129
luName: glauben.v
luID: 30016
lu_idx: [(21, 26, 1577)]
fe_idx: [(29, 60, 'Content', 697), (63, 125, 'Explanation', 8228), (17, 19, 'Cognizer', 695)]
tokenized_text: Wir saßen da und ich glaube , sie vertauschten die Reihenfolge , weil wir hinterher fragten : ' War das okay für dich ?' und er : ' Ja .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'glauben.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Certainty', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Cognizer', '-', '-', 'Content', 'Content', 'Content', 'Content', '-', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', '-']

===============================
====Annotation (`annoID` = 4396)====
text: The second is that it's put us in a place where we have no idea what's going to happen, in terms of the future.
frameName: Placing
frameID: 56
luName: put.v
luID: 14284
lu_idx: [(24, 26, 1)]
fe_idx: [(28, 29, 'Theme', 236), (19, 20, 'Cause', 1306), (31, 40, 'Goal', 239), (42, 46, 'Goal', 239)]
tokenized_text: The second is that it 's put us in a place where we have no idea what 's going to happen , in terms of the future .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'put.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Placing', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Cause', '-', '-', 'Theme', 'Goal', 'Goal', 'Goal', 'Goal', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9159)====
text: Zweitens befinden wir uns an einem Punkt, an dem wir keine Ahnung haben, wie es in Zukunft weitergeht.
frameName: Being_located
frameID: 481
luName: sich an einem Punkt befinden.v
luID: 29368
lu_idx: [(35, 39, 1577), (26, 27, 1577), (29, 33, 1577), (9, 16, 1577)]
fe_idx: [(42, 100, 'Location', 7882), (26, 41, 'Location', 7882), (18, 20, 'Theme', 3914)]
tokenized_text: Zweitens befinden wir uns an einem Punkt , an dem wir keine Ahnung haben , wie es in Zukunft weitergeht .
tokenized_lu_idx: ['-', 'sich an einem Punkt befinden.v', '-', '-', 'sich an einem Punkt befinden.v', 'sich an einem Punkt befinden.v', 'sich an einem Punkt befinden.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Being_located', '-', '-', 'Being_located', 'Being_located', 'Being_located', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Theme', '-', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', '-']

===============================
====Annotation (`annoID` = 9761)====
text: I have an interest in education.
frameName: Possession
frameID: 107
luName: have.v
luID: 16047
lu_idx: [(2, 5, 1)]
fe_idx: [(7, 30, 'Possession', 463), (0, 0, 'Owner', 457)]
tokenized_text: I have an interest in education .
tokenized_lu_idx: ['-', 'have.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Possession', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Possession', 'Possession', 'Possession', 'Possession', '-']

====Annotation (`annoID` = 10373)====
text: Ich interessiere mich für Bildung.
frameName: Experiencer_focus
frameID: 42
luName: interessiere mich.v
luID: 29853
lu_idx: [(17, 20, 1577), (4, 15, 1577)]
fe_idx: [(22, 32, 'Content', 169), (0, 2, 'Experiencer', 168)]
tokenized_text: Ich interessiere mich für Bildung .
tokenized_lu_idx: ['-', 'interessiere mich.v', 'interessiere mich.v', '-', '-', '-']
tokenized_frame_idx: ['-', 'Experiencer_focus', 'Experiencer_focus', '-', '-', '-']
tokenized_fe_idx: ['Experiencer', '-', '-', 'Content', 'Content', '-']


===============================
====Annotation (`annoID` = 4397)====
text: The second is that it's put us in a place where we have no idea what's going to happen, in terms of the future.
frameName: Locale
frameID: 172
luName: place.n
luID: 17435
lu_idx: [(36, 40, 1)]
fe_idx: [(36, 40, 'Locale', 987)]
tokenized_text: The second is that it 's put us in a place where we have no idea what 's going to happen , in terms of the future .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'place.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locale', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locale', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9159)====
text: Zweitens befinden wir uns an einem Punkt, an dem wir keine Ahnung haben, wie es in Zukunft weitergeht.
frameName: Being_located
frameID: 481
luName: sich an einem Punkt befinden.v
luID: 29368
lu_idx: [(35, 39, 1577), (26, 27, 1577), (29, 33, 1577), (9, 16, 1577)]
fe_idx: [(42, 100, 'Location', 7882), (26, 41, 'Location', 7882), (18, 20, 'Theme', 3914)]
tokenized_text: Zweitens befinden wir uns an einem Punkt , an dem wir keine Ahnung haben , wie es in Zukunft weitergeht .
tokenized_lu_idx: ['-', 'sich an einem Punkt befinden.v', '-', '-', 'sich an einem Punkt befinden.v', 'sich an einem Punkt befinden.v', 'sich an einem Punkt befinden.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Being_located', '-', '-', 'Being_located', 'Being_located', 'Being_located', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Theme', '-', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', '-']

===============================
====Annotation (`annoID` = 2507)====
text: What you have there is a person of extraordinary dedication who found a talent.
frameName: Locating
frameID: 458
luName: find.v
luID: 22270
lu_idx: [(64, 68, 1)]
fe_idx: [(70, 77, 'Sought_entity', 3534), (60, 62, 'Perceiver', 3533), (23, 58, 'Perceiver', 3533)]
tokenized_text: What you have there is a person of extraordinary dedication who found a talent .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'find.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locating', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Perceiver', 'Perceiver', 'Perceiver', 'Perceiver', 'Perceiver', 'Perceiver', '-', 'Sought_entity', 'Sought_entity', '-']

====Annotation (`annoID` = 9310)====
text: Sie ist eine Person mit außerordentlicher Hingabe, die ihr Talent gefunden hat.
frameName: Becoming_aware
frameID: 15
luName: finden.v
luID: 29518
lu_idx: [(66, 73, 1577)]
fe_idx: [(55, 58, 'Phenomenon', 62), (51, 53, 'Cognizer', 61), (59, 64, 'Phenomenon', 62)]
tokenized_text: Sie ist eine Person mit außerordentlicher Hingabe , die ihr Talent gefunden hat .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'finden.v', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Becoming_aware', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', 'Phenomenon', 'Phenomenon', '-', '-', '-']

===============================
====Annotation (`annoID` = 4271)====
text: And the third part of this is that we've all agreed, nonetheless, on the really extraordinary capacities that children have -- their capacities for innovation.
frameName: Stimulus_focus
frameID: 336
luName: extraordinary.a
luID: 27212
lu_idx: [(80, 92, 1)]
fe_idx: [(94, 103, 'Stimulus', 2400), (73, 78, 'Degree', 2402)]
tokenized_text: And the third part of this is that we 've all agreed , nonetheless , on the really extraordinary capacities that children have -- their capacities for innovation .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'extraordinary.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Stimulus_focus', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Degree', '-', 'Stimulus', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9716)====
text: Und das dritte Thema ist, dass wir uns trotzdem alle einig sind, dass Kinder wirklich außergewöhnliche Fähigkeiten haben -- Fähigkeiten, neue Wege zu gehen.
frameName: Desirability
frameID: 326
luName: außergewöhnlich.a
luID: 29781
lu_idx: [(86, 101, 1577)]
fe_idx: [(103, 113, 'Evaluee', 2309), (77, 84, 'Degree', 2310)]
tokenized_text: Und das dritte Thema ist , dass wir uns trotzdem alle einig sind , dass Kinder wirklich außergewöhnliche Fähigkeiten haben -- Fähigkeiten , neue Wege zu gehen .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'außergewöhnlich.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Desirability', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Degree', '-', 'Evaluee', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2561)====
text: And the girl said, 'They will, in a minute.'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(13, 16, 1)]
fe_idx: [(20, 41, 'Message', 154), (4, 11, 'Speaker', 152)]
tokenized_text: And the girl said , ' They will , in a minute . '
tokenized_lu_idx: ['-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 9347)====
text: Und das Mädchen antwortete: 'Gleich wissen sie es.'
frameName: Communication_response
frameID: 36
luName: antworten.v
luID: 29540
lu_idx: [(16, 25, 1577)]
fe_idx: [(4, 14, 'Speaker', 146), (29, 49, 'Message', 148)]
tokenized_text: Und das Mädchen antwortete : ' Gleich wissen sie es . '
tokenized_lu_idx: ['-', '-', '-', 'antworten.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Communication_response', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', '-']

===============================
====Annotation (`annoID` = 2449)====
text: They come in bearing gifts, gold, frankincense and myrrh.
frameName: Arriving
frameID: 48
luName: come.v
luID: 13943
lu_idx: [(5, 8, 1)]
fe_idx: [(13, 55, 'Circumstances', 6875), (10, 11, 'Goal', 189), (0, 3, 'Theme', 186)]
tokenized_text: They come in bearing gifts , gold , frankincense and myrrh .
tokenized_lu_idx: ['-', 'come.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Arriving', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Theme', '-', 'Goal', 'Circumstances', 'Circumstances', 'Circumstances', 'Circumstances', 'Circumstances', 'Circumstances', 'Circumstances', 'Circumstances', '-']

====Annotation (`annoID` = 10713)====
text: Sie bringen Geschenke, Gold, Weihrauch und Myrrhe.
frameName: Giving
frameID: 127
luName: bringen.v
luID: 29949
lu_idx: [(4, 10, 1577)]
fe_idx: [(0, 2, 'Donor', 672), (43, 48, 'Depictive', 8192), (12, 20, 'Theme', 674), (29, 37, 'Depictive', 8192), (23, 26, 'Depictive', 8192)]
tokenized_text: Sie bringen Geschenke , Gold , Weihrauch und Myrrhe .
tokenized_lu_idx: ['-', 'bringen.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Giving', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Donor', '-', 'Theme', '-', 'Depictive', '-', 'Depictive', '-', 'Depictive', '-']

===============================
====Annotation (`annoID` = 9765)====
text: My contention is that creativity now is as important in education as literacy, and we should treat it with the same status.
frameName: Identicality
frameID: 511
luName: same.a
luID: 22793
lu_idx: [(111, 114, 1)]
fe_idx: [(116, 121, 'Type', 4094), (111, 121, 'Current_instance', 4095)]
tokenized_text: My contention is that creativity now is as important in education as literacy , and we should treat it with the same status .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'same.a', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Identicality', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Current_instance', 'Current_instance', '-']

====Annotation (`annoID` = 9321)====
text: Meine Überzeugung ist, dass Kreativität heute genauso wichtig für Bildung ist, wie Lesen und Schreiben, und wir sollten sie gleichwertig behandeln.
frameName: Evaluative_comparison
frameID: 325
luName: gleichwertig.a
luID: 29523
lu_idx: [(124, 135, 1577)]
fe_idx: [(120, 122, 'Profiled_item', 2256)]
tokenized_text: Meine Überzeugung ist , dass Kreativität heute genauso wichtig für Bildung ist , wie Lesen und Schreiben , und wir sollten sie gleichwertig behandeln .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'gleichwertig.a', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Evaluative_comparison', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Profiled_item', '-', '-', '-']

====Annotation (`annoID` = 4517)====
text: He didn't have to speak, but you know the bit where the three kings come in?
frameName: Familiarity
frameID: 714
luName: know.v
luID: 24084
lu_idx: [(33, 36, 1)]
fe_idx: [(38, 74, 'Entity', 5868), (29, 31, 'Cognizer', 5869)]
tokenized_text: He did n't have to speak , but you know the bit where the three kings come in ?
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'know.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Familiarity', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', '-', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', '-']

====Annotation (`annoID` = 10775)====
text: Er musste nicht reden, aber wissen Sie noch, der Teil, wo die drei Könige kommen?
frameName: Remembering_information
frameID: 587
luName: wissen noch.v
luID: 30012
lu_idx: [(39, 42, 1577), (0, 0, 1577), (28, 33, 1577)]
fe_idx: [(45, 79, 'Mental_content', 4710), (35, 37, 'Cognizer', 4709)]
tokenized_text: Er musste nicht reden , aber wissen Sie noch , der Teil , wo die drei Könige kommen ?
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'wissen noch.v', '-', 'wissen noch.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Remembering_information', '-', 'Remembering_information', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Cognizer', '-', '-', 'Mental_content', 'Mental_content', 'Mental_content', 'Mental_content', 'Mental_content', 'Mental_content', 'Mental_content', 'Mental_content', '-']

===============================
====Annotation (`annoID` = 2489)====
text: We were sitting there and I think they just went out of sequence, because we talked to the little boy afterward and we said, 'You OK with that?'
frameName: Posture
frameID: 13
luName: sit.v
luID: 12743
lu_idx: [(8, 14, 1)]
fe_idx: [(16, 20, 'Location', 56), (0, 1, 'Agent', 55)]
tokenized_text: We were sitting there and I think they just went out of sequence , because we talked to the little boy afterward and we said , ' You OK with that ? '
tokenized_lu_idx: ['-', '-', 'sit.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Posture', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Agent', '-', '-', 'Location', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10715)====
text: Wir saßen da und ich glaube, sie vertauschten die Reihenfolge, weil wir hinterher fragten: 'War das okay für dich?'und er: 'Ja.
frameName: Perception_experience
frameID: 64
luName: dasitzen.v
luID: 29951
lu_idx: [(4, 8, 1577)]
fe_idx: [(0, 2, 'Perceiver_passive', 287)]
tokenized_text: Wir saßen da und ich glaube , sie vertauschten die Reihenfolge , weil wir hinterher fragten : ' War das okay für dich ?' und er : ' Ja .
tokenized_lu_idx: ['-', 'dasitzen.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Perception_experience', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Perceiver_passive', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2555)====
text: I heard a great story recently -- I love telling it -- of a little girl who was in a drawing lesson.
frameName: Statement
frameID: 37
luName: tell.v
luID: 13430
lu_idx: [(41, 47, 1)]
fe_idx: [(34, 34, 'Speaker', 152), (49, 50, 'Message', 154)]
tokenized_text: I heard a great story recently -- I love telling it -- of a little girl who was in a drawing lesson .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'tell.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', 'Message', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10794)====
text: Ich habe vor kurzem eine tolle Geschichte gehört -- ich erzähle sie zu gern -- über ein kleines Mädchen, die in Zeichnen saß.
frameName: Telling
frameID: 454
luName: erzählen.v
luID: 29759
lu_idx: [(56, 62, 1577)]
fe_idx: [(68, 74, 'Manner', 3506), (64, 66, 'Message', 3504), (52, 54, 'Speaker', 3502)]
tokenized_text: Ich habe vor kurzem eine tolle Geschichte gehört -- ich erzähle sie zu gern -- über ein kleines Mädchen , die in Zeichnen saß .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'erzählen.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Telling', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', 'Message', 'Manner', 'Manner', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4276)====
text: I mean, Sirena last night was a marvel, wasn't she?
frameName: Stimulus_focus
frameID: 336
luName: marvel.n
luID: 27215
lu_idx: [(32, 37, 1)]
fe_idx: [(8, 13, 'Stimulus', 2400)]
tokenized_text: I mean , Sirena last night was a marvel , was n't she ?
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'marvel.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Stimulus_focus', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Stimulus', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9304)====
text: Sirena gestern Abend war wunderbar, nicht wahr?
frameName: Desirability
frameID: 326
luName: wunderbar.a
luID: 29514
lu_idx: [(25, 33, 1577)]
fe_idx: [(0, 5, 'Evaluee', 2309), (7, 19, 'Circumstances', 2311)]
tokenized_text: Sirena gestern Abend war wunderbar , nicht wahr ?
tokenized_lu_idx: ['-', '-', '-', '-', 'wunderbar.a', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Desirability', '-', '-', '-', '-']
tokenized_fe_idx: ['Evaluee', 'Circumstances', 'Circumstances', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4057)====
text: And the girl said, 'I'm drawing a picture of God.'
frameName: Create_physical_artwork
frameID: 756
luName: draw.v
luID: 24326
lu_idx: [(24, 30, 1)]
fe_idx: [(21, 21, 'Creator', 6374), (32, 47, 'Representation', 6376)]
tokenized_text: And the girl said , ' I 'm drawing a picture of God . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'draw.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Create_physical_artwork', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Representation', 'Representation', 'Representation', 'Representation', '-', '-']

====Annotation (`annoID` = 9340)====
text: Und das Mädchen sagte: 'Ich zeichne ein Bild von Gott.'
frameName: Create_representation
frameID: 755
luName: zeichnen.v
luID: 29537
lu_idx: [(28, 34, 1577)]
fe_idx: [(36, 43, 'Representation', 6357), (45, 52, 'Represented', 6360), (24, 26, 'Creator', 6358)]
tokenized_text: Und das Mädchen sagte : ' Ich zeichne ein Bild von Gott . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'zeichnen.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Create_representation', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Creator', '-', 'Representation', 'Representation', 'Represented', 'Represented', '-', '-']

===============================
====Annotation (`annoID` = 4472)====
text: I heard a great story recently -- I love telling it -- of a little girl who was in a drawing lesson.
frameName: People
frameID: 278
luName: girl.n
luID: 19352
lu_idx: [(67, 70, 1)]
fe_idx: [(67, 70, 'Person', 1854), (72, 74, 'Person', 1854)]
tokenized_text: I heard a great story recently -- I love telling it -- of a little girl who was in a drawing lesson .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'girl.n', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'People', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Person', 'Person', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9327)====
text: Ich habe vor kurzem eine tolle Geschichte gehört -- ich erzähle sie zu gern -- über ein kleines Mädchen, die in Zeichnen saß.
frameName: People_by_age
frameID: 490
luName: mädchen.n
luID: 29529
lu_idx: [(96, 102, 1577)]
fe_idx: [(105, 123, 'Descriptor', 3966), (-1, -1, 'Age', 3967), (-1, -1, 'Person', 3964), (88, 94, 'Persistent_characteristic', 3965)]
tokenized_text: Ich habe vor kurzem eine tolle Geschichte gehört -- ich erzähle sie zu gern -- über ein kleines Mädchen , die in Zeichnen saß .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'mädchen.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'People_by_age', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Persistent_characteristic', '-', '-', 'Descriptor', 'Descriptor', 'Descriptor', 'Descriptor', '-']

===============================
====Annotation (`annoID` = 2532)====
text: So I want to talk about education and I want to talk about creativity.
frameName: Statement
frameID: 37
luName: talk.v
luID: 13411
lu_idx: [(48, 51, 1)]
fe_idx: [(38, 38, 'Speaker', 152), (53, 68, 'Topic', 155)]
tokenized_text: So I want to talk about education and I want to talk about creativity .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'talk.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', '-', 'Topic', 'Topic', '-']

====Annotation (`annoID` = 9724)====
text: Ich möchte also über Bildung und Kreativität sprechen.
frameName: Speak_on_topic
frameID: 424
luName: sprechen.v
luID: 29788
lu_idx: [(45, 52, 1577)]
fe_idx: [(16, 43, 'Topic', 3125), (0, 2, 'Speaker', 3124)]
tokenized_text: Ich möchte also über Bildung und Kreativität sprechen .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'sprechen.v', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Speak_on_topic', '-']
tokenized_fe_idx: ['Speaker', '-', '-', 'Topic', 'Topic', 'Topic', 'Topic', '-', '-']

===============================
====Annotation (`annoID` = 4411)====
text: And you're never asked back, curiously.
frameName: Locative_relation
frameID: 179
luName: back.avp
luID: 27281
lu_idx: [(23, 26, 1)]
fe_idx: [(4, 6, 'Figure', 1030), (-1, -1, 'Profiled_region', 11219)]
tokenized_text: And you 're never asked back , curiously .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'back.avp', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Locative_relation', '-', '-', '-']
tokenized_fe_idx: ['-', 'Figure', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9266)====
text: Auf jeden Fall nicht zweimal, seltsamerweise.
frameName: Frequency
frameID: 74
luName: zweimal.adv
luID: 29488
lu_idx: [(21, 27, 1577)]
fe_idx: [(-1, -1, 'Attribute', 6005)]
tokenized_text: Auf jeden Fall nicht zweimal , seltsamerweise .
tokenized_lu_idx: ['-', '-', '-', '-', 'zweimal.adv', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Frequency', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4224)====
text: Just seeing what she could do.
frameName: Intentionally_act
frameID: 178
luName: do.v
luID: 17683
lu_idx: [(27, 28, 1)]
fe_idx: [(17, 19, 'Agent', 1024), (12, 15, 'Act', 1023)]
tokenized_text: Just seeing what she could do .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'do.v', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Intentionally_act', '-']
tokenized_fe_idx: ['-', '-', 'Act', 'Agent', '-', '-', '-']

====Annotation (`annoID` = 9097)====
text: Allein zu sehen, wozu sie in der Lage ist.
frameName: Capability
frameID: 496
luName: in der Lage sein.v
luID: 29340
lu_idx: [(38, 40, 1577), (33, 36, 1577), (29, 31, 1577), (26, 27, 1577)]
fe_idx: [(17, 20, 'Event', 4000), (22, 24, 'Entity', 3999)]
tokenized_text: Allein zu sehen , wozu sie in der Lage ist .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'in der Lage sein.v', 'in der Lage sein.v', 'in der Lage sein.v', 'in der Lage sein.v', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Capability', 'Capability', 'Capability', 'Capability', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Event', 'Entity', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2423)====
text: But if you ask about their education, they pin you to the wall.
frameName: Attaching
frameID: 177
luName: pin.v
luID: 17634
lu_idx: [(43, 45, 1)]
fe_idx: [(47, 49, 'Item', 1021), (51, 61, 'Goal', 1485), (38, 41, 'Agent', 1020)]
tokenized_text: But if you ask about their education , they pin you to the wall .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'pin.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Attaching', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Agent', '-', 'Item', 'Goal', 'Goal', 'Goal', '-']

====Annotation (`annoID` = 10420)====
text: Fragen Sie sie nach ihrer Schulbildung, nageln sie Sie an die Wand.
frameName: Retaining
frameID: 1160
luName: an die Wand nageln.v
luID: 29369
lu_idx: [(40, 45, 1577)]
fe_idx: [(47, 49, 'Agent', 10819), (51, 53, 'Theme', 10820), (55, 65, 'Place', 10822)]
tokenized_text: Fragen Sie sie nach ihrer Schulbildung , nageln sie Sie an die Wand .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'an die Wand nageln.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Retaining', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Agent', 'Theme', 'Place', 'Place', 'Place', '-']

===============================
====Annotation (`annoID` = 2526)====
text: And yet we're meant to be educating them for it.
frameName: Purpose
frameID: 416
luName: mean.v
luID: 21664
lu_idx: [(14, 18, 1)]
fe_idx: [(20, 46, 'Goal', 3090), (-1, -1, 'Agent', 3089), (8, 9, 'Goal', 3090)]
tokenized_text: And yet we 're meant to be educating them for it .
tokenized_lu_idx: ['-', '-', '-', '-', 'mean.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Purpose', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Goal', '-', '-', 'Goal', 'Goal', 'Goal', 'Goal', 'Goal', 'Goal', '-']

====Annotation (`annoID` = 9297)====
text: Und trotzdem sollen wir sie dafür ausbilden.
frameName: Being_obligated
frameID: 361
luName: sollen.v
luID: 29511
lu_idx: [(13, 18, 1577)]
fe_idx: [(20, 22, 'Responsible_party', 2602), (24, 42, 'Duty', 2603)]
tokenized_text: Und trotzdem sollen wir sie dafür ausbilden .
tokenized_lu_idx: ['-', '-', 'sollen.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Being_obligated', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Responsible_party', 'Duty', 'Duty', 'Duty', '-']

===============================
====Annotation (`annoID` = 2540)====
text: There have been three themes running through the conference which are relevant to what I want to talk about.
frameName: Discussion
frameID: 28
luName: talk (to).v
luID: 13195
lu_idx: [(97, 100, 1)]
fe_idx: [(87, 87, 'Interlocutor_1', 109), (-1, -1, 'Interlocutor_2', 110), (102, 106, 'Topic', 112), (82, 85, 'Topic', 112)]
tokenized_text: There have been three themes running through the conference which are relevant to what I want to talk about .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'talk (to).v', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Discussion', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Topic', 'Interlocutor_1', '-', '-', '-', 'Topic', '-']

====Annotation (`annoID` = 9438)====
text: Es gab drei Leitmotive, die sich durch die Konferenz zogen, die wichtig sind für das, worüber ich sprechen will.
frameName: Text_creation
frameID: 253
luName: sprechen.v
luID: 29637
lu_idx: [(98, 105, 1577)]
fe_idx: [(94, 96, 'Author', 1684), (-1, -1, 'Text', 1686)]
tokenized_text: Es gab drei Leitmotive , die sich durch die Konferenz zogen , die wichtig sind für das , worüber ich sprechen will .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'sprechen.v', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Text_creation', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Author', '-', '-', '-']

===============================
====Annotation (`annoID` = 4421)====
text: But if you are, and you say to somebody, you know, they say, 'What do you do?'and you say you work in education, you can see the blood run from their face.
frameName: Substance
frameID: 609
luName: blood.n
luID: 27283
lu_idx: [(129, 133, 1)]
fe_idx: [(129, 133, 'Substance', 4968)]
tokenized_text: But if you are , and you say to somebody , you know , they say , ' What do you do ?' and you say you work in education , you can see the blood run from their face .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'blood.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Substance', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Substance', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10378)====
text: Sind Sie aber eingeladen und reden mit jemandem, also wenn jemand fragt: 'Was machen Sie so?'und Sie: 'Ich arbeite im Bildungswesen', sieht man, wie den anderen das Blut aus dem Gesicht weicht.
frameName: Body_parts
frameID: 108
luName: das Blut.n
luID: 29858
lu_idx: [(165, 168, 1577), (161, 163, 1577)]
fe_idx: [(149, 159, 'Possessor', 472), (174, 184, 'Orientational_location', 522)]
tokenized_text: Sind Sie aber eingeladen und reden mit jemandem , also wenn jemand fragt : ' Was machen Sie so ?' und Sie : ' Ich arbeite im Bildungswesen ' , sieht man , wie den anderen das Blut aus dem Gesicht weicht .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'das Blut.n', 'das Blut.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Body_parts', 'Body_parts', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Possessor', 'Possessor', '-', '-', '-', 'Orientational_location', 'Orientational_location', '-', '-']

===============================
====Annotation (`annoID` = 2554)====
text: I heard a great story recently -- I love telling it -- of a little girl who was in a drawing lesson.
frameName: Hearsay
frameID: 31
luName: hear.v
luID: 13218
lu_idx: [(2, 6, 1)]
fe_idx: [(55, 98, 'Message', 123), (0, 0, 'Hearer', 122), (22, 29, 'Time', 9430), (8, 20, 'Message', 123)]
tokenized_text: I heard a great story recently -- I love telling it -- of a little girl who was in a drawing lesson .
tokenized_lu_idx: ['-', 'hear.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Hearsay', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Message', 'Message', 'Message', 'Time', '-', '-', '-', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-']

====Annotation (`annoID` = 10784)====
text: Ich habe vor kurzem eine tolle Geschichte gehört -- ich erzähle sie zu gern -- über ein kleines Mädchen, die in Zeichnen saß.
frameName: Perception_experience
frameID: 64
luName: gehört haben.v
luID: 30020
lu_idx: [(42, 47, 1577), (0, 0, 1577), (4, 7, 1577)]
fe_idx: []
tokenized_text: Ich habe vor kurzem eine tolle Geschichte gehört -- ich erzähle sie zu gern -- über ein kleines Mädchen , die in Zeichnen saß .
tokenized_lu_idx: ['-', 'gehört haben.v', '-', '-', '-', '-', '-', 'gehört haben.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Perception_experience', '-', '-', '-', '-', '-', 'Perception_experience', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9668)====
text: He didn't have to speak, but you know the bit where the three kings come in?
frameName: Leadership
frameID: 67
luName: king.n
luID: 14768
lu_idx: [(62, 66, 1)]
fe_idx: [(62, 66, 'Leader', 303)]
tokenized_text: He did n't have to speak , but you know the bit where the three kings come in ?
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'king.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Leadership', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Leader', '-', '-', '-']

====Annotation (`annoID` = 10737)====
text: Er musste nicht reden, aber wissen Sie noch, der Teil, wo die drei Könige kommen?
frameName: People_by_jurisdiction
frameID: 506
luName: könig.n
luID: 29984
lu_idx: [(67, 72, 1577)]
fe_idx: [(67, 72, 'Person', 4061)]
tokenized_text: Er musste nicht reden , aber wissen Sie noch , der Teil , wo die drei Könige kommen ?
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'könig.n', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'People_by_jurisdiction', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Person', '-', '-']

===============================
====Annotation (`annoID` = 9760)====
text: The second is that it's put us in a place where we have no idea what's going to happen, in terms of the future.
frameName: Possession
frameID: 107
luName: have.v
luID: 16047
lu_idx: [(51, 54, 1)]
fe_idx: [(56, 62, 'Possession', 463), (64, 67, 'Possession', 463), (48, 49, 'Owner', 457)]
tokenized_text: The second is that it 's put us in a place where we have no idea what 's going to happen , in terms of the future .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'have.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Possession', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Owner', '-', 'Possession', 'Possession', 'Possession', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9094)====
text: Zweitens befinden wir uns an einem Punkt, an dem wir keine Ahnung haben, wie es in Zukunft weitergeht.
frameName: Awareness
frameID: 14
luName: keine Ahnung haben.v
luID: 29337
lu_idx: [(59, 64, 1577), (66, 70, 1577), (53, 57, 1577)]
fe_idx: [(49, 51, 'Cognizer', 57), (73, 100, 'Topic', 60), (53, 57, 'Degree', 638)]
tokenized_text: Zweitens befinden wir uns an einem Punkt , an dem wir keine Ahnung haben , wie es in Zukunft weitergeht .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'keine Ahnung haben.v', 'keine Ahnung haben.v', 'keine Ahnung haben.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Awareness', 'Awareness', 'Awareness', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', 'Degree', '-', '-', '-', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', '-']

===============================
====Annotation (`annoID` = 9662)====
text: And she's exceptional, but I think she's not, so to speak, exceptional in the whole of childhood.
frameName: Age
frameID: 489
luName: childhood.n
luID: 27284
lu_idx: [(87, 95, 1)]
fe_idx: [(-1, -1, 'Entity', 3957)]
tokenized_text: And she 's exceptional , but I think she 's not , so to speak , exceptional in the whole of childhood .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'childhood.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Age', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10798)====
text: Sie ist außergewöhnlich, aber ich denke, sie ist nicht, sozusagen, außergewöhnlich in Bezug auf die Gesamtheit aller Kinder.
frameName: People_by_age
frameID: 490
luName: kind.n
luID: 29504
lu_idx: [(117, 122, 1577)]
fe_idx: []
tokenized_text: Sie ist außergewöhnlich , aber ich denke , sie ist nicht , sozusagen , außergewöhnlich in Bezug auf die Gesamtheit aller Kinder .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'kind.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'People_by_age', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4404)====
text: No idea how this may play out.
frameName: Turning_out
frameID: 959
luName: play.v
luID: 27277
lu_idx: [(21, 24, 1)]
fe_idx: [(8, 10, 'State_of_affairs', 9175), (12, 15, 'State_of_affairs', 9175)]
tokenized_text: No idea how this may play out .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'play.v', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Turning_out', '-', '-']
tokenized_fe_idx: ['-', '-', 'State_of_affairs', 'State_of_affairs', '-', '-', '-', '-']

====Annotation (`annoID` = 9691)====
text: Keine Ahnung, wie das enden wird.
frameName: Process_end
frameID: 208
luName: enden.v
luID: 29756
lu_idx: [(22, 26, 1577)]
fe_idx: [(18, 20, 'Process', 1404), (14, 16, 'Manner', 1411)]
tokenized_text: Keine Ahnung , wie das enden wird .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'enden.v', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Process_end', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Manner', 'Process', '-', '-', '-']

===============================
====Annotation (`annoID` = 2490)====
text: We were sitting there and I think they just went out of sequence, because we talked to the little boy afterward and we said, 'You OK with that?'
frameName: Motion
frameID: 3
luName: go.v
luID: 12554
lu_idx: [(44, 47, 1)]
fe_idx: [(49, 63, 'Manner', 2265), (34, 37, 'Theme', 11)]
tokenized_text: We were sitting there and I think they just went out of sequence , because we talked to the little boy afterward and we said , ' You OK with that ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'go.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Motion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Theme', '-', '-', 'Manner', 'Manner', 'Manner', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10717)====
text: Wir saßen da und ich glaube, sie vertauschten die Reihenfolge, weil wir hinterher fragten: 'War das okay für dich?'und er: 'Ja.
frameName: Bungling
frameID: 241
luName: vertauschen.v
luID: 29953
lu_idx: [(33, 44, 1577)]
fe_idx: [(29, 31, 'Agent', 1564), (46, 60, 'Patient', 1565), (33, 44, 'Action', 1569)]
tokenized_text: Wir saßen da und ich glaube , sie vertauschten die Reihenfolge , weil wir hinterher fragten : ' War das okay für dich ?' und er : ' Ja .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'vertauschen.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Bungling', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Agent', 'Action', 'Patient', 'Patient', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9812)====
text: At the top are mathematics and languages, then the humanities, and at the bottom are the arts.
frameName: Part_orientational
frameID: 131
luName: bottom.n
luID: 16640
lu_idx: [(74, 79, 1)]
fe_idx: [(-1, -1, 'Whole', 707), (85, 92, 'Part', 705)]
tokenized_text: At the top are mathematics and languages , then the humanities , and at the bottom are the arts .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'bottom.n', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Part_orientational', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Part', 'Part', '-']

====Annotation (`annoID` = 1410)====
text: No topo estão a matemática e as línguas, depois as humanas e por último as artes.
frameName: Time_vector
frameID: 349
luName: por último.adv
luID: 26521
lu_idx: [(61, 70, 453)]
fe_idx: [(-1, -1, 'Distance', 2502), (3, 57, 'Event', 3489), (-1, -1, 'Direction', 2503), (-1, -1, 'Landmark_event', 2501)]
tokenized_text: No topo estão a matemática e as línguas , depois as humanas e por último as artes .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'por último.adv', 'por último.adv', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Time_vector', 'Time_vector', '-', '-', '-']
tokenized_fe_idx: ['-', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2566)====
text: We were sitting there and I think they just went out of sequence, because we talked to the little boy afterward and we said, 'You OK with that?'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(119, 122, 1)]
fe_idx: [(126, 141, 'Message', 154), (116, 117, 'Speaker', 152)]
tokenized_text: We were sitting there and I think they just went out of sequence , because we talked to the little boy afterward and we said , ' You OK with that ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 6680)====
text: Estávamos lá sentados e eu acho que eles não seguiram a ordem porque nós conversamos com o garotinho depois e perguntamos: 'Tudo certo?'
frameName: Questioning
frameID: 34
luName: perguntar.v
luID: 26573
lu_idx: [(110, 120, 453)]
fe_idx: [(124, 134, 'Message', 138), (89, 99, 'Addressee', 137), (-1, -1, 'Topic', 139), (69, 71, 'Speaker', 136)]
tokenized_text: Estávamos lá sentados e eu acho que eles não seguiram a ordem porque nós conversamos com o garotinho depois e perguntamos : ' Tudo certo ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'perguntar.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Questioning', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', 'Addressee', 'Addressee', '-', '-', '-', '-', '-', 'Message', 'Message', 'Message', '-']

===============================
====Annotation (`annoID` = 9761)====
text: I have an interest in education.
frameName: Possession
frameID: 107
luName: have.v
luID: 16047
lu_idx: [(2, 5, 1)]
fe_idx: [(7, 30, 'Possession', 463), (0, 0, 'Owner', 457)]
tokenized_text: I have an interest in education .
tokenized_lu_idx: ['-', 'have.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Possession', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Possession', 'Possession', 'Possession', 'Possession', '-']

====Annotation (`annoID` = 4296)====
text: Eu me interesso por educação.
frameName: Mental_stimulus_exp_focus
frameID: 910
luName: interessar - se.v
luID: 27230
lu_idx: [(3, 14, 453)]
fe_idx: [(0, 1, 'Experiencer', 8514), (16, 27, 'Topic', 8515)]
tokenized_text: Eu me interesso por educação .
tokenized_lu_idx: ['-', 'interessar - se.v', 'interessar - se.v', '-', '-', '-']
tokenized_frame_idx: ['-', 'Mental_stimulus_exp_focus', 'Mental_stimulus_exp_focus', '-', '-', '-']
tokenized_fe_idx: ['Experiencer', '-', '-', 'Topic', 'Topic', '-']

===============================
====Annotation (`annoID` = 10033)====
text: Truthfully, what happens is, as children grow up, we start to educate them progressively from the waist up.
frameName: Aging
frameID: 855
luName: grow up.v
luID: 29809
lu_idx: [(41, 44, 1), (46, 47, 1)]
fe_idx: [(32, 39, 'Entity', 7907)]
tokenized_text: Truthfully , what happens is , as children grow up , we start to educate them progressively from the waist up .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'grow up.v', 'grow up.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Aging', 'Aging', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Entity', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1592)====
text: Sério, o que acontece é que à medida que as crianças crescem, nós começamos a educá-las progressivamente da cintura para cima.
frameName: Transition_to_state
frameID: 521
luName: crescer.v
luID: 26584
lu_idx: [(53, 59, 453)]
fe_idx: [(44, 51, 'Entity', 4166), (-1, -1, 'Final_category', 4168)]
tokenized_text: Sério , o que acontece é que à medida que as crianças crescem , nós começamos a educá-las progressivamente da cintura para cima .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'crescer.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Transition_to_state', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Entity', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4227)====
text: Actually, what I find is everybody has an interest in education.
frameName: Emotion_directed
frameID: 40
luName: interest.n
luID: 13643
lu_idx: [(42, 49, 1)]
fe_idx: [(51, 62, 'Topic', 164), (25, 33, 'Experiencer', 163)]
tokenized_text: Actually , what I find is everybody has an interest in education .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'interest.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Emotion_directed', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Experiencer', '-', '-', '-', 'Topic', 'Topic', '-']

====Annotation (`annoID` = 4299)====
text: Na verdade, eu descobri que todo mundo se interessa por educação.
frameName: Mental_stimulus_exp_focus
frameID: 910
luName: interessar - se.v
luID: 27230
lu_idx: [(39, 50, 453)]
fe_idx: [(28, 37, 'Experiencer', 8514), (52, 63, 'Topic', 8515)]
tokenized_text: Na verdade , eu descobri que todo mundo se interessa por educação .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'interessar - se.v', 'interessar - se.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Mental_stimulus_exp_focus', 'Mental_stimulus_exp_focus', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Experiencer', 'Experiencer', '-', '-', 'Topic', 'Topic', '-']

===============================
====Annotation (`annoID` = 2415)====
text: Actually, we lived in a place called Snitterfield, just outside Stratford, which is where Shakespeare's father was born.
frameName: Interior_profile_relation
frameID: 570
luName: outside.prep
luID: 23276
lu_idx: [(56, 62, 1)]
fe_idx: [(75, 79, 'Ground', 4551), (51, 54, 'Directness', 11179), (64, 72, 'Ground', 4551), (24, 48, 'Figure', 4550)]
tokenized_text: Actually , we lived in a place called Snitterfield , just outside Stratford , which is where Shakespeare 's father was born .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'outside.prep', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Interior_profile_relation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Figure', 'Figure', 'Figure', '-', 'Directness', '-', 'Ground', '-', 'Ground', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1248)====
text: Na verdade, nós moramos numa cidade chamada Snitterfield, na periferia de Stratford, que foi onde o pai do Shakespeare nasceu.
frameName: Origin
frameID: 533
luName: de.prep
luID: 26351
lu_idx: [(71, 72, 453)]
fe_idx: [(74, 82, 'Origin', 4348), (61, 69, 'Entity', 4347)]
tokenized_text: Na verdade , nós moramos numa cidade chamada Snitterfield , na periferia de Stratford , que foi onde o pai do Shakespeare nasceu .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'de.prep', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Origin', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Entity', '-', 'Origin', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2250)====
text: Somebody else might have put her on medication and told her to calm down.
frameName: Placing
frameID: 56
luName: put.v
luID: 14284
lu_idx: [(25, 27, 1)]
fe_idx: [(33, 45, 'Goal', 239), (0, 7, 'Agent', 235), (29, 31, 'Theme', 236)]
tokenized_text: Somebody else might have put her on medication and told her to calm down .
tokenized_lu_idx: ['-', '-', '-', '-', 'put.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Placing', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Agent', '-', '-', '-', '-', 'Theme', 'Goal', 'Goal', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2258)====
text: Outra pessoa poderia ter receitado um remédio e dito para ela se acalmar.
frameName: Medical_intervention
frameID: 1152
luName: receitar.v
luID: 26641
lu_idx: [(25, 33, 453)]
fe_idx: [(0, 11, 'Medical_professional', 11240), (35, 44, 'Intervention', 10728)]
tokenized_text: Outra pessoa poderia ter receitado um remédio e dito para ela se acalmar .
tokenized_lu_idx: ['-', '-', '-', '-', 'receitar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Medical_intervention', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Medical_professional', 'Medical_professional', '-', '-', '-', 'Intervention', 'Intervention', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9618)====
text: I believe this passionately, that we don't grow into creativity, we grow out of it.
frameName: Transition_to_state
frameID: 521
luName: grow.v
luID: 22831
lu_idx: [(43, 46, 1)]
fe_idx: [(34, 35, 'Entity', 4166), (48, 62, 'Final_quality', 4167)]
tokenized_text: I believe this passionately , that we do n't grow into creativity , we grow out of it .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'grow.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Transition_to_state', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Entity', '-', '-', '-', 'Final_quality', 'Final_quality', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1085)====
text: Eu acredito apaixonadamente que não aumentamos nossa criatividade, a diminuímos.
frameName: Cause_expansion
frameID: 71
luName: aumentar.v
luID: 26341
lu_idx: [(36, 45, 453)]
fe_idx: [(-1, -1, 'Agent', 316), (47, 64, 'Item', 317), (-1, -1, 'Cause', 3276)]
tokenized_text: Eu acredito apaixonadamente que não aumentamos nossa criatividade , a diminuímos .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'aumentar.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Cause_expansion', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Item', 'Item', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10113)====
text: When I was a student, if you had a degree, you had a job.
frameName: Rank
frameID: 629
luName: degree.n
luID: 23614
lu_idx: [(35, 40, 1)]
fe_idx: [(35, 40, 'Rank', 5118), (-1, -1, 'Item', 6514)]
tokenized_text: When I was a student , if you had a degree , you had a job .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'degree.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Rank', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Rank', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7298)====
text: Quando eu estudava, quem tinha um diploma, tinha um emprego.
frameName: Documents
frameID: 429
luName: diploma.n
luID: 28458
lu_idx: [(34, 40, 453)]
fe_idx: [(20, 23, 'Bearer', 3135), (-1, -1, 'Issuer', 3136), (-1, -1, 'Document', 3141), (-1, -1, 'Obligation', 3137)]
tokenized_text: Quando eu estudava , quem tinha um diploma , tinha um emprego .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'diploma.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Documents', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Bearer', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2589)====
text: Anyway, Gillian and I had lunch one day and I said, 'How did you get to be a dancer?'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(46, 49, 1)]
fe_idx: [(44, 44, 'Speaker', 152), (53, 82, 'Message', 154)]
tokenized_text: Anyway , Gillian and I had lunch one day and I said , ' How did you get to be a dancer ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 7535)====
text: Gillian e eu almoçamos um dia e eu perguntei: 'Gillian, como você se tornou dançarina?'
frameName: Questioning
frameID: 34
luName: perguntar.v
luID: 26573
lu_idx: [(35, 43, 453)]
fe_idx: [(32, 33, 'Speaker', 136), (47, 84, 'Message', 138), (-1, -1, 'Addressee', 137)]
tokenized_text: Gillian e eu almoçamos um dia e eu perguntei : ' Gillian , como você se tornou dançarina ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'perguntar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Questioning', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']


===============================
====Annotation (`annoID` = 9664)====
text: Actually, he was four everywhere, to be honest.
frameName: Locative_relation
frameID: 179
luName: everywhere.adv
luID: 17715
lu_idx: [(22, 31, 1)]
fe_idx: [(10, 20, 'Figure', 1030), (22, 31, 'Ground', 1029)]
tokenized_text: Actually , he was four everywhere , to be honest .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'everywhere.adv', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Locative_relation', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Figure', 'Figure', 'Figure', 'Ground', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6790)====
text: Na verdade ela tinha quatro anos em qualquer lugar, pra ser sincero.
frameName: Locale
frameID: 172
luName: lugar.n
luID: 26517
lu_idx: [(45, 49, 453)]
fe_idx: [(-1, -1, 'Locale', 987)]
tokenized_text: Na verdade ela tinha quatro anos em qualquer lugar , pra ser sincero .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'lugar.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Locale', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2605)====
text: If you were to visit education, as an alien, and say 'What's it for, public education?'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(49, 51, 1)]
fe_idx: [(54, 84, 'Message', 154), (3, 5, 'Speaker', 152)]
tokenized_text: If you were to visit education , as an alien , and say ' What 's it for , public education ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 1872)====
text: Se você visitasse nossas escolas, como um ET, e se perguntasse: 'Para que serve a educação pública?'
frameName: Questioning
frameID: 34
luName: perguntar.v
luID: 26573
lu_idx: [(51, 61, 453)]
fe_idx: [(48, 49, 'Addressee', 137), (-1, -1, 'Topic', 139), (-1, -1, 'Speaker', 136), (65, 98, 'Message', 138)]
tokenized_text: Se você visitasse nossas escolas , como um ET , e se perguntasse : ' Para que serve a educação pública ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'perguntar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Questioning', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Addressee', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-']

===============================
====Annotation (`annoID` = 2600)====
text: She said, 'She did.
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(4, 7, 1)]
fe_idx: [(11, 17, 'Message', 154), (0, 2, 'Speaker', 152)]
tokenized_text: She said , ' She did .
tokenized_lu_idx: ['-', 'say.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Statement', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Speaker', '-', '-', '-', 'Message', 'Message', '-']

====Annotation (`annoID` = 6978)====
text: Ela respondeu: Ela levou.
frameName: Communication_response
frameID: 36
luName: responder.v
luID: 27240
lu_idx: [(4, 12, 453)]
fe_idx: [(0, 2, 'Speaker', 146), (-1, -1, 'Addressee', 147), (-1, -1, 'Trigger', 151), (15, 23, 'Message', 148)]
tokenized_text: Ela respondeu : Ela levou .
tokenized_lu_idx: ['-', 'responder.v', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Communication_response', '-', '-', '-', '-']
tokenized_fe_idx: ['Speaker', '-', '-', 'Message', 'Message', '-']

===============================
====Annotation (`annoID` = 9823)====
text: Everywhere on Earth.
frameName: Locative_relation
frameID: 179
luName: everywhere.adv
luID: 17715
lu_idx: [(0, 9, 1)]
fe_idx: [(11, 18, 'Ground', 1029), (-1, -1, 'Figure', 1030)]
tokenized_text: Everywhere on Earth .
tokenized_lu_idx: ['everywhere.adv', '-', '-', '-']
tokenized_frame_idx: ['Locative_relation', '-', '-', '-']
tokenized_fe_idx: ['-', 'Ground', 'Ground', '-']

====Annotation (`annoID` = 1400)====
text: Qualquer lugar do planeta.
frameName: Locale
frameID: 172
luName: lugar.n
luID: 26517
lu_idx: [(9, 13, 453)]
fe_idx: [(15, 24, 'Relative_location', 989), (-1, -1, 'Locale', 987)]
tokenized_text: Qualquer lugar do planeta .
tokenized_lu_idx: ['-', 'lugar.n', '-', '-', '-']
tokenized_frame_idx: ['-', 'Locale', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Relative_location', 'Relative_location', '-']

===============================
====Annotation (`annoID` = 10168)====
text: We think visually, we think in sound, we think kinesthetically.
frameName: Sensation
frameID: 65
luName: sound.n
luID: 14715
lu_idx: [(31, 35, 1)]
fe_idx: [(31, 35, 'Percept', 297)]
tokenized_text: We think visually , we think in sound , we think kinesthetically .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'sound.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Sensation', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Percept', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7368)====
text: Pensamos visualmente, pensamos auditivamente, pensamos cinestesicamente.
frameName: Manner
frameID: 1044
luName: auditivamente.adv
luID: 28487
lu_idx: [(31, 43, 453)]
fe_idx: [(-1, -1, 'Salient_entity', 9755), (-1, -1, 'Manner', 9756), (22, 29, 'Comparison_activity', 9764), (-1, -1, 'Comparison_event', 9754), (-1, -1, 'Manner_descriptor', 9757)]
tokenized_text: Pensamos visualmente , pensamos auditivamente , pensamos cinestesicamente .
tokenized_lu_idx: ['-', '-', '-', '-', 'auditivamente.adv', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Manner', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Comparison_activity', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 8791)====
text: I used to be on the board of The Royal Ballet, as you can see.
frameName: Organization
frameID: 625
luName: board.n
luID: 23594
lu_idx: [(20, 24, 1)]
fe_idx: [(26, 44, 'Container_possessor', 7123), (0, 0, 'Members', 5101)]
tokenized_text: I used to be on the board of The Royal Ballet , as you can see .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'board.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Organization', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Container_possessor', 'Container_possessor', 'Container_possessor', 'Container_possessor', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7527)====
text: Eu estava no conselho do Royal Ballet, na Inglaterra, como podem ver.
frameName: Social_event
frameID: 114
luName: conselho.n
luID: 28568
lu_idx: [(13, 20, 453)]
fe_idx: [(22, 36, 'Host', 549), (-1, -1, 'Social_event', 546), (0, 1, 'Attendee', 552)]
tokenized_text: Eu estava no conselho do Royal Ballet , na Inglaterra , como podem ver .
tokenized_lu_idx: ['-', '-', '-', 'conselho.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Social_event', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Attendee', '-', '-', '-', 'Host', 'Host', 'Host', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4509)====
text: But James got the part of Joseph, which we were thrilled about.
frameName: Getting
frameID: 161
luName: get.v
luID: 17150
lu_idx: [(10, 12, 1)]
fe_idx: [(14, 31, 'Theme', 872), (4, 8, 'Recipient', 871)]
tokenized_text: But James got the part of Joseph , which we were thrilled about .
tokenized_lu_idx: ['-', '-', 'get.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Getting', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Recipient', '-', 'Theme', 'Theme', 'Theme', 'Theme', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6602)====
text: Mas o James ganhou o papel de José, o que nos deixou empolgados.
frameName: Receiving
frameID: 380
luName: ganhar.v
luID: 28186
lu_idx: [(12, 17, 453)]
fe_idx: [(4, 10, 'Recipient', 3149), (19, 33, 'Theme', 3151), (-1, -1, 'Donor', 3150)]
tokenized_text: Mas o James ganhou o papel de José , o que nos deixou empolgados .
tokenized_lu_idx: ['-', '-', '-', 'ganhar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Receiving', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Recipient', 'Recipient', '-', 'Theme', 'Theme', 'Theme', 'Theme', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10258)====
text: And the third thing about intelligence is, it's distinct.
frameName: Entity
frameID: 226
luName: thing.n
luID: 18380
lu_idx: [(14, 18, 1)]
fe_idx: [(14, 18, 'Entity', 1843)]
tokenized_text: And the third thing about intelligence is , it 's distinct .
tokenized_lu_idx: ['-', '-', '-', 'thing.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Entity', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Entity', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7471)====
text: O terceiro ponto sobre a inteligência é que é distinta.
frameName: Topic
frameID: 343
luName: ponto.n
luID: 28533
lu_idx: [(11, 15, 453)]
fe_idx: [(-1, -1, 'Communicator', 2454), (17, 36, 'Topic', 2452), (-1, -1, 'Text', 2453)]
tokenized_text: O terceiro ponto sobre a inteligência é que é distinta .
tokenized_lu_idx: ['-', '-', 'ponto.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Topic', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Topic', 'Topic', 'Topic', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9613)====
text: And the result is that we are educating people out of their creative capacities.
frameName: Capability
frameID: 496
luName: capacity.n
luID: 22698
lu_idx: [(69, 78, 1)]
fe_idx: [(54, 58, 'Entity', 3999), (60, 67, 'Relevant_feature', 4923)]
tokenized_text: And the result is that we are educating people out of their creative capacities .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'capacity.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Capability', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Entity', 'Relevant_feature', '-', '-']

====Annotation (`annoID` = 2205)====
text: O resultado disso é que estamos educando as pessoas para serem menos criativas.
frameName: Mental_property
frameID: 24
luName: criativo.a
luID: 26419
lu_idx: [(69, 77, 453)]
fe_idx: [(-1, -1, 'Behavior', 95), (41, 50, 'Protagonist', 94), (63, 67, 'Degree', 932)]
tokenized_text: O resultado disso é que estamos educando as pessoas para serem menos criativas .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'criativo.a', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Mental_property', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Protagonist', 'Protagonist', '-', '-', 'Degree', '-', '-']

===============================
====Annotation (`annoID` = 10001)====
text: They all came into being to meet the needs of industrialism.
frameName: Coming_to_be
frameID: 288
luName: come to be.v
luID: 19529
lu_idx: [(9, 12, 1), (19, 23, 1), (14, 17, 1)]
fe_idx: [(25, 58, 'Explanation', 1953), (0, 3, 'Entity', 1950)]
tokenized_text: They all came into being to meet the needs of industrialism .
tokenized_lu_idx: ['-', '-', 'come to be.v', 'come to be.v', 'come to be.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Coming_to_be', 'Coming_to_be', 'Coming_to_be', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Entity', '-', '-', '-', '-', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', '-']

====Annotation (`annoID` = 6984)====
text: Todos eles foram criados para atender a demanda da industrialização.
frameName: Creating
frameID: 291
luName: criar.v
luID: 28328
lu_idx: [(17, 23, 453)]
fe_idx: [(25, 66, 'Purpose', 5850), (0, 9, 'Created_entity', 2791), (-1, -1, 'Creator', 5849)]
tokenized_text: Todos eles foram criados para atender a demanda da industrialização .
tokenized_lu_idx: ['-', '-', '-', 'criar.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Creating', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Created_entity', 'Created_entity', '-', '-', 'Purpose', 'Purpose', 'Purpose', 'Purpose', 'Purpose', 'Purpose', '-']


